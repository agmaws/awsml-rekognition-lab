{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "In this lab, we will see how to take a video and run it through Amazon Rekognition Video to extract the following:\n",
    "\n",
    "1. Text - Find text in the video\n",
    "1. Content Moderation Labels - Is the video suitable for viewing; rate the video for violence, gore, nudity, etc.\n",
    "1. Labels - Find labels in the video, including objects (tree), events (birthday), activities (skiing)\n",
    "\n",
    "The following AWS services are used in this lab:\n",
    "\n",
    "* **IAM** : Identity and Access Management, mostly for Permissions and Roles  \n",
    "* **Amazon Rekognition** : Computer Vision API  \n",
    "* **SNS**: Simple Notification Service, used by Rekognition to provide status of a job (mostly for applications), we will bypass most of its functionality for this lab  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IAM and Access\n",
    "AWS Identity and Access Management (IAM) enables you to manage access to AWS services and resources.  \n",
    "In the next few steps we will add some permissions for our code to run.\n",
    "\n",
    "1. Create a Role which gives Rekognition permissions to use SNS  \n",
    "In this step we are just creating the Role. This new Role will be referenced in Step 3 below.  \n",
    "\n",
    " * In IAM Console select create role\n",
    " * In the next screen select Rekognition\n",
    " * Click next all the way to the end and give this role a name, such as:  \"rekognition_access_to_sns\"\n",
    "<br>\n",
    "\n",
    "2. Add *RekognitionFullAccess* and *SNSFullAccess* to the Sagemaker Execution Role  \n",
    "![](smexecutionrole.png)\n",
    "\n",
    " * Go to the IAM service and click Roles\n",
    " * Click the SageMaker Execution Role\n",
    " * Click \"Attach Policies\"\n",
    " * In the list of services, search for *Rekognition* and then select *RekognitionFullAccess* \n",
    " * In the list of services, search for *SNS* and then select *SNSFullAccess* \n",
    " * Click \"Attach policies\"\n",
    "<br>\n",
    "\n",
    "![](rekservicerole.png)\n",
    "\n",
    "3. Attach an inline Policy to the SageMaker Execution Role which allows passing the Role created in Step 2 to Rekognition\n",
    " * Click \"Add inline policy\"\n",
    " * Select the JSON tab\n",
    " * Copy and paste the following Policy into the text box\n",
    " * Replace the \"Resource\" with the ARN of the Role you created in Step 1 above\n",
    " * Click \"Review policy\"\n",
    " * Type a name for this inline Policy and click \"Attach policy\"\n",
    "```yaml\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"rekoginitRekogPass\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"iam:PassRole\",\n",
    "            \"Resource\": \"arn:aws:iam::xxxxxxxx:role/rekognition_access_to_sns\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import some standard libraries to be used by our python code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's declare some variable of where our video file is and its name etc .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name of the S3 bucket where the video to be analyzed will be stored\n",
    "bucket = '<ENTER YOUR BUCKET NAME HERE>'\n",
    "\n",
    "# the location of the video file to be analyzied\n",
    "video_url = \"https://ia801703.us.archive.org/1/items/2020-01-06_videos-WashingtonDC-Propublica/bjXvAoK0Gu5Fcvt.mp4\"\n",
    "\n",
    "# just the name of the video file\n",
    "video = os.path.basename(video_url)\n",
    "\n",
    "# the ARN of the Role created in Step 2: IAM and Access\n",
    "RekognitionSnsRoleArn = '<ENTER YOUR REKOGNITION ROLE ARN HERE>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a copy of the video from the source location\n",
    "!curl $video_url --output $video\n",
    "!aws s3 cp $video \"s3://$bucket/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate boto3 clients for Rekognition and SNS\n",
    "The boto3 library is the AWS SDK for Python which makes it easy to integrate your Python application, library, or script with AWS services. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rek = boto3.client('rekognition')\n",
    "sns = boto3.client('sns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need a SNS Topic to track the progress of Rekognition Video \n",
    "A message is sent to the SNS topic when the video analysis is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sns.create_topic(Name='rekVideoStatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicArn = response['TopicArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Rekgonition Video Text Detection API\n",
    "Amazon Rekognition text detection can detect text in videos, converting the detected text into machine-readable text. It can read skewed and distorted text to capture information like store names, forced narratives overlaid on media, street signs, and text on product packaging.  \n",
    "\n",
    "The *start_text_detection* API call initiates the video analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rek.start_text_detection(Video={'S3Object': {'Bucket': bucket, 'Name': video}},\n",
    "            NotificationChannel={'RoleArn': RekognitionSnsRoleArn , 'SNSTopicArn': topicArn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobId = response['JobId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "When you execute the cell below, if the job is still in progress we will see JobStatus as \"IN PROGRESS\".  \n",
    "If it is complete, JobStatus will be set to \"SUCCEEDED\" and we will get the first MaxResults (10 in this example) results.  \n",
    "For this exercise, we can invoke the API call repeatedly using Ctrl-Enter to run this cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rek.get_text_detection(\n",
    "    JobId=jobId,\n",
    "    MaxResults=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving all the results...\n",
    "If we want more (or all) the results, we can use a while Loop until 'NextToken' is empty, like so:\n",
    "\n",
    "```yaml\n",
    "results=[]\n",
    "paginationToken = ''\n",
    "finished = False\n",
    "\n",
    "while finished == False:\n",
    "    '''if you want to just read it into a list'''\n",
    "    temp = rek.get_text_detection(\n",
    "        JobId = jobId,\n",
    "        MaxResults = 10,\n",
    "        NextToken = paginationToken\n",
    "    )\n",
    "    results += temp['TextDetections']\n",
    "    paginationToken = temp['NextToken']\n",
    "    if len(paginationToken) == 0:\n",
    "        finished = True\n",
    "    \n",
    "'''if you want to write to file'''\n",
    "with open(filename, 'a+') as f:\n",
    "    f.write(\"parsed results here\")\n",
    "        \n",
    "'''of you can use a csv writer if you want a csv file'''\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rekognition Video Content Moderation API\n",
    "With Amazon Rekognition you can detect explicit adult or suggestive content, violence, weapons, drugs, tobacco, alcohol, hate symbols, gambling, disturbing content, and rude gestures in both images and videos, and get back a confidence score for each detected label.  \n",
    "\n",
    "All we change in the code is the call to *start_content_moderation*, quite simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rek.start_content_moderation(Video={'S3Object': {'Bucket': bucket, 'Name': video}},\n",
    "            NotificationChannel={'RoleArn': RekognitionSnsRoleArn, 'SNSTopicArn': topicArn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobId = response['JobId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rek.get_content_moderation(\n",
    "    JobId=jobId,\n",
    "    MaxResults=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rekognition Video Label Detection\n",
    "With Amazon Rekognition, you can identify thousands of objects (such as bike, telephone, building), and scenes (such as parking lot, beach, city). You can also identify specific activities such as \"delivering a package\" or \"playing soccer\".  \n",
    "\n",
    "All we change here is the API call to *start_object_detection*, again - quite simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rek.start_label_detection(Video={'S3Object': {'Bucket': bucket, 'Name': video}},\n",
    "            NotificationChannel={'RoleArn': RekognitionSnsRoleArn, 'SNSTopicArn': topicArn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobId = response['JobId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rek.get_label_detection(\n",
    "    JobId = jobId,\n",
    "    MaxResults = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
